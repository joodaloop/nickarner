---
title: "Projects"
date: "2022-01-01"
layout: "has-contents"
---


## Work

* Meter - MacOS VPN App | 2023

* **[Roboflow iOS SDK](/projects_and_work/work/roboflow_native_mobile_sdk/)** | 2023

* Dusty Robotics - iPad app for construction robot control

* Tlon - iOS Chat app for Urbit 

* Asteroid - No-Code AR Development Tool | 2018-2019

  

## Personal

* **[Peer-to-Peer Audio Chat iOS App](/projects_and_work/personal/push_to_talk_audio_chat_app/)** | 2019

* **[Whistlr - Audio QR-Code Contact Sharing iOS App]((/projects_and_work/whistlr/))** | 2017

* **[Swept Frequency Capacitive Sensing (Touch√©) Experiments](/projects_and_work/personal/emulating_touche/)** | 2017

* **[MM-Wave Radar Interfaces: Project Soli Alpha Developer Program](/projects_and_work/personal/o_soli_mio/)** |  2016-2017

* **[Delay Tracker: iOS App for Reporting Amtrak Delays](/projects_and_work/personal/delay_tracker/)** | 2015

  

## Open source



- **Running Shell Commands from Screenshots**

  

**Detecting Flame Strength with a Bluetooth Sensor and iPhone** | 2017 

I wanted to learn about Bluetooth, so I built a system that would transmit data from a flame sensor to an iOS app using Bluetooth LE. The hardware setup used a flame sensor and an [Arduino Flora board](https://www.adafruit.com/product/659). The iOS app was written in Swift and used CoreBluetooth for the data communication. 

GitHub repo [here](https://github.com/narner/iOS-FlameSensor-Bluetooth-Study) + blog post [here](/notes/integrating-arduino-bluetooth-sensors-with-ios-september-5-2017/).

**Analog and NeoPixel LED Strip Controls with Arduino**| 2017 

At the time, I was prototyping some physical product ideas that needed a lighting system. I built a multiplexing system for controlling a strip of analog LED's, as well as a digital Adafruit NeoPixel strip. GitHub repo [here](https://github.com/narner/Analog-and-NeoPixel-LED-Strip-Control). 

**ML-based Gesture Recognition on iOS** | 2017 

In the pre-CoreML era, I built an app that could detect the type of gestures you were making with your iPhone via the CoreMotion framework's access to the phone's accelerometer. It utilized a C++ library called the [Gesture Recognition Toolkit](https://github.com/nickgillian/grt). I wrote an Objective-C++ wrapper around the library for use with Swift, and built an app with both on-device training + real-time prediction modes.  

GitHub repo [here](https://github.com/narner/GRT-iOS-HelloWorld) + blog post [here](/notes/machine-learning-powered-gesture-recognition-on-ios-october-7-2017/).

**Arduino Controlled macOS Synthesizer** | 2015 

I built an AudioKit-powered macOS synthesizer that was controlled by an Arduino circuit. Data from the potentiometers and switch connected to the Arduino was read by the macOS app over the USB serial port, and used to control the synthesizer parameters. GitHub repo [here](https://github.com/narner/Arduino-AudioKitOSX). 





* **Detecting ASL Signs on iOS** | 2021

I built a demo app that can detect American Sign Language signs using computer vision. The CoreML model was created using David Lee's American Sign Language Letters Dataset, which is hosted on Roboflow [here](https://public.roboflow.com/object-detection/american-sign-language-letters). The GitHub repo for the app is [here](https://github.com/narner/ASL-Classifier-Demo).

**Dyscalculia Tester App** | 2020

[Dyscalculia](https://www.dyscalculia.org) is a learning disorder that results in difficulty learning or comprehending mathematics (sometimes called "math dyslexia"). I built a prototype of an iOS app consisting of [two types of tests](https://www.youtube.com/watch?v=p_Hqdqe84Uc&t=231s) for dyscalculia developed by cognitive neuroscientist [Dr. Brian Butterworth](https://www.dyscalculia.org/experts/brian-butterworth). GitHub repo [here](https://github.com/narner/DyscalculiaTester).



* **[AudioKit](/projects_and_work/audiokit/)** | 2014-2016



---











