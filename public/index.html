<!DOCTYPE html>
<html>
<head>
	<meta name="generator" content="Hugo 0.68.3" />
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Nick Arner  </title><meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="alternate" type="application/rss+xml" href="http://example.org/index.xml" title="Nick Arner" />
	<meta property="og:title" content="Nick Arner" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://example.org/" />
<meta property="og:updated_time" content="2020-04-07T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Nick Arner"/>
<meta name="twitter:description" content=""/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="http://example.org/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="http://example.org/css/main.css" />

	
	<script src="http://example.org/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	<h1 class="site-title"><a href="http://example.org/">Nick Arner</a></h1>
	<div class="site-description"><nav class="nav social">
			<ul class="flat"></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
		</ul>
	</nav>
</div>


		<div class="recent-posts section">
			<h2 class="section-header">
				Recent posts
			</h2>
			<div class="posts">
				
				
				
				<div class="post">
					<div class="meta">Apr 7, 2020 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/project-soli-the-coming-use-of-radar-in-human-machine-interfaces/">Project Soli &amp; the Coming Use of Radar in Human-Machine Interfaces</a> &mdash;
					<span class="description">
						
						Radar is a 85 — year old technology that up until recently has not been actively deployed in human-machine interfaces. Radar — based gesture sensing allows user intent to be inferred across more contexts than optical-only based tracking currently allows.
Google’s use of Project Soli, a radar-based gesture recognition system, in the Pixel 4 series of phones is most likely the first step in further adoption of radar as an input for interacting with our devices.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Oct 29, 2019 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/classification-of-sound-files-on-ios-with-the-soundanalysis-framework-and-esc-10-coreml-model-october-29-2019/">Classification of Sound Files on iOS with the SoundAnalysis Framework and ESC-10 CoreML Model</a> &mdash;
					<span class="description">
						
						Earlier this year, Apple introduced the SoundAnalysis framework, enabling apps to “analyze streamed and file-based audio to classify it as a particular type”.
It’s available in the following SDK’s:
 iOS13+ macOS 10.15+ Mac Catalyst 13.0+ tvOS 13.0+ watchOS 6.0+  INPUT TYPES The SoundAnalysis framework is able to work with live audio via the device microphone, or from pre-recorded audio files. In a real-world application scenario, these could be either audio files downloaded from a server onto the app, or recorded by the app for later analysis.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Oct 14, 2019 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/machine-learning-development-on-apple-platforms-october-14-2019/">Machine Learning Development on Apple Platforms</a> &mdash;
					<span class="description">
						
						Machine Learning Development on Apple Platforms Apple has been investing heavily in machine learning (ML) capabilities for its development platforms. Acquisitions of applied ML startups allows Apple to fold their technology into the hardware, operating system, and software development tooling for their products. Creating developer friendly frameworks makes it easy to leverage the ML capabilities of Apple’s computing devices, allowing for a greater number of apps that can apply ML in a wider array of use cases.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Sep 27, 2019 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/things-a-first-time-pm-should-know-about-ios-development-september-22-2019/">Things a First Time PM Should Know About iOS Development</a> &mdash;
					<span class="description">
						
						This post is a modification of some notes I wrote for a friend, who was recently hired for their first Project Management position at a startup that is developing an iOS app. They don&rsquo;t have a technical background, and wanted to know what some fundamental things to know about iOS development, the iOS ecosystem, and workflows of development.
I modified those notes for this blogpost. Feel free to reach out at nicholasarner@gmail.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Oct 7, 2017 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/machine-learning-powered-gesture-recognition-on-ios-octobober-7-2017/">Machine-Learning powered Gesture Recognition on iOS</a> &mdash;
					<span class="description">
						
						It’s almost hard not to be reading about machine learning these days — and that trend will only increase. Machine learning is opening up powerful new capabilities for smartphone apps, from image classification to facial recognition.
It’s also capable of identifying how someone is interacting with their smartphone.
This project shows how to use the Gesture Recognition Toolkit to detect how a user is moving their phone through physical space. (I wrote up a quick guide here on how to begin integrating the GRT into an iPhone app project).&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Oct 3, 2017 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/jazz-gestures-and-open-source-why-and-how-i-learned-to-code-october-3-2017/">Jazz, Gestures, and Open-Source - Why and How I Learned to Code</a> &mdash;
					<span class="description">
						
						Inspired by a conversation with Diana Berlin, I wrote about what motivates me as a technologist, and the personal story behind why and how I learned to code.
I published the piece on Medium here, and am including it below as an archive:
 There’s been lots of discussion lately on how many people working as software developers “started off doing something else” before they learned to code…often meaning that they studied something other than computer science in college.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Sep 5, 2017 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/integrating-arduino-bluetooth-sensors-with-ios-september-5-2017/">Integrating Arduino-Bluetooth Sensors with iOS</a> &mdash;
					<span class="description">
						
						One area that I&rsquo;ve been exploring recently is Bluetooth communication between sensor-circuits and iOS apps. I wanted to share one of these studies, based on some of the examples provided from the good folks at Adafruit. It consists of a sensor that can detect the presence of a flame, and send that information over Bluetooth to an iPhone app, which displays the reading from the sensor.
Here&rsquo;s what it looks like in action:&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Aug 29, 2017 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/integrating-the-grt-into-an-iphone-project-august-29-2017/">Integrating the GRT into an iPhone Project</a> &mdash;
					<span class="description">
						
						In this blog post, I&rsquo;ll show you to add the Gesture Recognition Toolkit to an iPhone app. Created by Nick GIllian while he was a post-doc at MIT, the GRT is a &ldquo;cross-platform, open-source, C++ machine learning library designed for real-time gesture recognition&rdquo;. I had known from this issue on GitHub that the GRT has been used in iOS development. I was only able to find one example of this in action, which this guide is partially based upon.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Aug 21, 2017 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/real-time-data-receiving-and-rendering-in-processing-august-21-2017/">Real-time data receiving and rendering in Processing</a> &mdash;
					<span class="description">
						
						Real-time data receiving and rendering in Processing - August 21, 2017 I wanted to talk a little bit about one of the technical challenges I had faced while writing the Processing receiver sketches for the Touché experiments in some previous blog posts (here and here).
The problem I was experiencing was that the Processing sketches that would receive the gesture-classification data from the ESP program seemed to updating incredibly slowly. As in, I could clearly see the gesture-classification results being updated in the ESP program, but in the Processing receiver sketches, the results would be displayed several seconds behind what the ESP system was sending!&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Aug 15, 2017 <span class="draft-label">DRAFT</span> </div>
					<a class="title" href="/posts/touche%CC%81-and-water-as-an-interface-august-15-2017/">Touché, and Water as an Interface</a> &mdash;
					<span class="description">
						
						After experimenting with learning how Touché could be used to interact with plants, I wanted to see how I could use it to interact with water.
In the Touché paper, the authors demonstrate that the sensor is capable of detecting how a user is touching the surface of, or submerging their hand in water. The system is able to distinguish among a variety of touch interactions: no hand, 1 finger, 3 fingers, and hand submerged:&hellip;
						
					</span>
				</div>
				
				

<ul class="pagination">
	<li class="page-item page-prev">
	
	</li>
	<li class="page-item page-next">
	
    <a href="/page/2/" class="page-link" aria-label="Next"><span aria-hidden="true">Next page →</span></a>
	
	</li>
</ul>


			</div>
		</div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> <a href="https://github.com/vividvilla/ezhil">Ezhil theme</a> | Built with <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>




</body>
</html>
